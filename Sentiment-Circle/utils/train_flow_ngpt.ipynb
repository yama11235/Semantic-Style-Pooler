{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# train.py フロー検証 (nGPT classifier)\n",
        "\n",
        "`Sentiment-Circle/utils/demo2.ipynb` と同じ方針で、`train.py` の実行ステップを 1 つずつ追跡しながら **nGPT 分類器** をテストできるようにした検証ノートブックです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. 準備\n",
        "- `train.py` で定義されているデータセット前処理・トレーナー初期化の関数を直接呼び出し、フローをそのまま再現します。\n",
        "- Weights & Biases 連携はデバッグ用途なので無効化しています (`WANDB_MODE=disabled`)。\n",
        "- `Train_df.csv` / `Valid_df.csv` / `Test_df.csv` から少数サンプルを取り、計算負荷を抑えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import sys\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoTokenizer, PrinterCallback\n",
        "\n",
        "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
        "os.environ.setdefault(\"WANDB_MODE\", \"disabled\")\n",
        "os.environ.setdefault(\"WANDB_DISABLED\", \"true\")\n",
        "\n",
        "PROJECT_ROOT = pathlib.Path('..').resolve()\n",
        "UTILS_DIR = PROJECT_ROOT / 'utils'\n",
        "DATASET_DIR = PROJECT_ROOT / 'dataset'\n",
        "OUTPUT_ROOT = PROJECT_ROOT / 'outputs'\n",
        "OUTPUT_ROOT.mkdir(exist_ok=True)\n",
        "\n",
        "sys.path.append(str(UTILS_DIR))\n",
        "\n",
        "from train import (\n",
        "    ModelArguments,\n",
        "    DataTrainingArguments,\n",
        "    TrainingArguments,\n",
        "    load_raw_datasets,\n",
        "    prepare_label_mappings,\n",
        ")\n",
        "from dataset_preprocessing import batch_get_preprocessing_function, get_preprocessing_function\n",
        "from model.modeling_utils import DataCollatorForBiEncoder, get_model\n",
        "from clf_trainer import CustomTrainer\n",
        "from progress_logger import LogCallback\n",
        "from model.nGPT_model import NGPTWeightNormCallback\n",
        "from metrics import compute_metrics\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ハイパーパラメータとクラス分類器設定\n",
        "`train.sh` のデフォルト値 (学習率・エポック数など) を参考にしつつ、デバッグしやすいようにバッチサイズとサンプル数だけ縮小しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModelArguments(model_name_or_path='mixedbread-ai/mxbai-embed-large-v1', config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, use_flash_attention='eager', device_map=None, encoding_type='bi_encoder', pooler_type='avg', freeze_encoder=True, transform=False, classifier_configs='/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/outputs/ngpt_classifier_config.json', corr_labels=None, corr_weights=None, aspect_key=None, objective='regression')\n",
            "DataTrainingArguments(max_seq_length=512, overwrite_cache=False, pad_to_max_length=False, max_train_samples=64, max_eval_samples=64, max_predict_samples=64, train_file=['/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/dataset/Train_df.csv'], validation_file=['/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/dataset/Valid_df.csv'], test_file=['/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/dataset/Test_df.csv'], max_similarity=None, min_similarity=None)\n",
            "TrainingArguments(\n",
            "_n_gpu=2,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=5,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "log_time_interval=15,\n",
            "logging_dir=/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/outputs/ngpt_debug_run/runs/Nov16_12-11-33_doremi,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.CONSTANT,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/outputs/ngpt_debug_run,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/outputs/ngpt_debug_run,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.NO,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "wandb_project=sentiment_circle,\n",
            "wandb_project_name=sentiment_info_nce_ngpt_demo,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "POOLER_TYPE = \"avg\"\n",
        "MAX_SEQ_LENGTH = 512\n",
        "LEARNING_RATE = 1e-4\n",
        "TRAIN_BATCH_SIZE = 32   # train.sh の 128 だとメモリを圧迫するため縮小\n",
        "EVAL_BATCH_SIZE = 64    # train.sh の 256 から縮小\n",
        "NUM_EPOCHS = 1\n",
        "GRAD_ACCUM = 1\n",
        "LOGGING_STEPS = 5\n",
        "EVAL_STEPS = 5\n",
        "MAX_TRAIN_SAMPLES = 64\n",
        "MAX_EVAL_SAMPLES = 64\n",
        "MAX_PRED_SAMPLES = 64\n",
        "\n",
        "classifier_config = {\n",
        "    \"sentiment\": {\n",
        "        \"type\": \"nGPT\",\n",
        "        \"layer\": -1,\n",
        "        \"objective\": \"infoNCE\",\n",
        "        \"distance\": \"cosine\",\n",
        "        \"pooler_type\": POOLER_TYPE,\n",
        "        \"dropout\": 0.1,\n",
        "        \"bias\": False,\n",
        "        \"base_scale\": 0.03125\n",
        "    }\n",
        "}\n",
        "CLASSIFIER_CONFIG_PATH = OUTPUT_ROOT / \"ngpt_classifier_config.json\"\n",
        "with open(CLASSIFIER_CONFIG_PATH, \"w\") as f:\n",
        "    json.dump(classifier_config, f, indent=2)\n",
        "\n",
        "model_args = ModelArguments(\n",
        "    model_name_or_path=MODEL_NAME,\n",
        "    pooler_type=POOLER_TYPE,\n",
        "    encoding_type=\"bi_encoder\",\n",
        "    freeze_encoder=True,\n",
        "    classifier_configs=str(CLASSIFIER_CONFIG_PATH),\n",
        ")\n",
        "\n",
        "data_args = DataTrainingArguments(\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    max_train_samples=MAX_TRAIN_SAMPLES,\n",
        "    max_eval_samples=MAX_EVAL_SAMPLES,\n",
        "    max_predict_samples=MAX_PRED_SAMPLES,\n",
        "    train_file=[str(DATASET_DIR / \"Train_df.csv\")],\n",
        "    validation_file=[str(DATASET_DIR / \"Valid_df.csv\")],\n",
        "    test_file=[str(DATASET_DIR / \"Test_df.csv\")],\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(OUTPUT_ROOT / \"ngpt_debug_run\"),\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    eval_steps=EVAL_STEPS,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"no\",\n",
        "    bf16=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    do_predict=True,\n",
        "    report_to=[\"none\"],\n",
        "    wandb_project_name=\"sentiment_info_nce_ngpt_demo\",\n",
        "    wandb_project=\"sentiment_circle\",\n",
        "    seed=42,\n",
        ")\n",
        "training_args.remove_unused_columns = False\n",
        "\n",
        "print(model_args)\n",
        "print(data_args)\n",
        "print(training_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. データセット読み込み\n",
        "`load_raw_datasets` で `Train/Valid/Test` を読み込み、必要であれば `sentence1` 列へリネームします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-16 12:11:37,196 - train - INFO: Load train files: ['/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/dataset/Train_df.csv']\n",
            "2025-11-16 12:11:37,198 - train - INFO: Load validation files: ['/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/dataset/Valid_df.csv']\n",
            "2025-11-16 12:11:37,198 - train - INFO: Load test files: ['/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/dataset/Test_df.csv']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence1', 'labels'],\n",
            "        num_rows: 64\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence1', 'labels'],\n",
            "        num_rows: 64\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence1', 'labels'],\n",
            "        num_rows: 64\n",
            "    })\n",
            "})\n",
            "sentence3 flag: False\n",
            "{'sentence1': 'is cold and wished to go back to bed', 'labels': 'relief'}\n"
          ]
        }
      ],
      "source": [
        "raw_datasets, sentence3_flag = load_raw_datasets(\n",
        "    model_args=model_args,\n",
        "    data_args=data_args,\n",
        "    training_args=training_args,\n",
        "    seed=training_args.seed,\n",
        ")\n",
        "print(raw_datasets)\n",
        "print(f\"sentence3 flag: {sentence3_flag}\")\n",
        "print(raw_datasets[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ラベルマッピング & クラス分類器辞書\n",
        "CSV の `labels` 列を `sentiment` に付け替え、`nGPT` 分類器設定を `prepare_label_mappings` に渡します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels: ['labels']\n",
            "aspect_key: ['sentiment']\n",
            "classifier configs: {\n",
            "  \"sentiment\": {\n",
            "    \"type\": \"nGPT\",\n",
            "    \"layer\": -1,\n",
            "    \"objective\": \"infoNCE\",\n",
            "    \"distance\": \"cosine\",\n",
            "    \"output_dim\": 256,\n",
            "    \"dropout\": 0.1,\n",
            "    \"bias\": false,\n",
            "    \"base_scale\": 0.03125\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    raw_datasets,\n",
        "    labels,\n",
        "    id2label,\n",
        "    label2id,\n",
        "    aspect_key,\n",
        "    classifier_configs,\n",
        "    classifier_configs_for_trainer,\n",
        "    corr_labels,\n",
        "    corr_weights,\n",
        "    label_name_mappings,\n",
        ") = prepare_label_mappings(\n",
        "    raw_datasets=raw_datasets,\n",
        "    model_args=model_args,\n",
        "    data_args=data_args,\n",
        ")\n",
        "print(f\"labels: {labels}\")\n",
        "print(f\"aspect_key: {aspect_key}\")\n",
        "print(f\"classifier configs: {json.dumps(classifier_configs, indent=2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Config / Tokenizer / モデル (nGPT 判定込み)\n",
        "ここから `train.py` と同様に `AutoConfig` / `AutoTokenizer` をロードし、nGPT ブロック検出によって最適化条件を調整します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at mixedbread-ai/mxbai-embed-large-v1 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2025-11-16 12:17:11,683 - model.modeling_encoders - INFO: Detected nGPT-style classifier block(s); applying initial weight normalization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "use_ngpt_blocks: True\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
        "    use_fast=model_args.use_fast_tokenizer,\n",
        ")\n",
        "\n",
        "model_cls = get_model(model_args)\n",
        "config.update(\n",
        "    {\n",
        "        \"freeze_encoder\": model_args.freeze_encoder,\n",
        "        \"model_name_or_path\": model_args.model_name_or_path,\n",
        "        \"pooler_type\": model_args.pooler_type,\n",
        "        \"transform\": model_args.transform,\n",
        "        \"attn_implementation\": model_args.use_flash_attention,\n",
        "        \"device_map\": model_args.device_map,\n",
        "    }\n",
        ")\n",
        "labels_for_heads = list(classifier_configs_for_trainer.keys())\n",
        "id2_head = {i: head for i, head in enumerate(labels_for_heads)}\n",
        "model = model_cls(model_config=config, classifier_configs=classifier_configs)\n",
        "\n",
        "if model_args.freeze_encoder:\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "use_ngpt_riemann = bool(getattr(model, \"use_ngpt_blocks\", False))\n",
        "print(f\"use_ngpt_blocks: {use_ngpt_riemann}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1a681628",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BiEncoderForClassification(\n",
              "  (backbone): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): Pooler()\n",
              "  (embedding_classifiers): ModuleDict(\n",
              "    (sentiment): nGPTClassifier(\n",
              "      (projection): Block(\n",
              "        (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (att_c_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (c_fc): Linear(in_features=1024, out_features=8192, bias=False)\n",
              "        (silu): SiLU()\n",
              "        (mlp_c_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. トークナイズと特徴量生成\n",
        "`get_preprocessing_function` / `batch_get_preprocessing_function` を選び、`DatasetDict.map` で `tokenizer` を実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f45ec6a86c294662944500019893dc41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/64 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "310131ab3b0443ce856c008ce84ce9eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/64 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed2a7c26591048be80ecdcf2b5102061",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/64 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'input_ids_2', 'attention_mask_2', 'token_type_ids_2', 'active_heads', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "padding = \"longest\" if data_args.pad_to_max_length else False\n",
        "max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)\n",
        "if sentence3_flag:\n",
        "    preprocess_function = batch_get_preprocessing_function(\n",
        "        tokenizer=tokenizer,\n",
        "        sentence1_key=\"sentence1\",\n",
        "        sentence2_key=\"sentence2\",\n",
        "        sentence3_key=\"sentence3\",\n",
        "        sentence3_flag=sentence3_flag,\n",
        "        aspect_key=aspect_key,\n",
        "        padding=padding,\n",
        "        max_seq_length=max_seq_length,\n",
        "        model_args=model_args,\n",
        "        scale=None,\n",
        "    )\n",
        "    batched = True\n",
        "else:\n",
        "    preprocess_function = get_preprocessing_function(\n",
        "        tokenizer=tokenizer,\n",
        "        sentence1_key=\"sentence1\",\n",
        "        sentence2_key=\"sentence2\",\n",
        "        sentence3_key=\"sentence3\",\n",
        "        sentence3_flag=sentence3_flag,\n",
        "        aspect_key=aspect_key,\n",
        "        padding=padding,\n",
        "        max_seq_length=max_seq_length,\n",
        "        model_args=model_args,\n",
        "        scale=None,\n",
        "    )\n",
        "    batched = False\n",
        "\n",
        "processed_datasets = raw_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=batched,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")\n",
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"validation\"]\n",
        "predict_dataset = processed_datasets[\"test\"]\n",
        "print(train_dataset[0].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c20761cc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2003, 3147, 1998, 6257, 2000, 2175, 2067, 2000, 2793, 102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids_2': None,\n",
              " 'attention_mask_2': None,\n",
              " 'token_type_ids_2': None,\n",
              " 'active_heads': ['sentiment'],\n",
              " 'labels': [8]}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. DataCollator / Trainer 構築\n",
        "`CustomTrainer` を初期化し、nGPT 用の正規化コールバックやメトリクス関数を登録します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/clf_trainer.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "collator_dtype = getattr(config, \"torch_dtype\", torch.float32)\n",
        "data_collator = DataCollatorForBiEncoder(\n",
        "    tokenizer=tokenizer,\n",
        "    padding=\"max_length\",\n",
        "    pad_to_multiple_of=None,\n",
        "    dtype=collator_dtype,\n",
        ")\n",
        "\n",
        "trainer_ref = {\"trainer\": None}\n",
        "\n",
        "def train_centroid_getter():\n",
        "    trainer_obj = trainer_ref[\"trainer\"]\n",
        "    if trainer_obj is None:\n",
        "        return {}\n",
        "    return trainer_obj.get_train_label_centroids()\n",
        "\n",
        "def compute_fn(eval_pred):\n",
        "    trainer_obj = trainer_ref[\"trainer\"]\n",
        "    embedding_mode = \"classifier\"\n",
        "    if trainer_obj is not None and getattr(trainer_obj, \"use_original_eval_embeddings\", False):\n",
        "        embedding_mode = \"original\"\n",
        "    return compute_metrics(\n",
        "        eval_pred,\n",
        "        classifier_configs=classifier_configs_for_trainer,\n",
        "        id2_head=id2_head,\n",
        "        train_centroid_getter=train_centroid_getter,\n",
        "        embedding_eval_mode=embedding_mode,\n",
        "    )\n",
        "\n",
        "ngpt_callback = NGPTWeightNormCallback(enabled=use_ngpt_riemann)\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    classifier_configs=classifier_configs_for_trainer,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_fn,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[LogCallback, ngpt_callback],\n",
        "    dtype=collator_dtype,\n",
        "    corr_labels=corr_labels,\n",
        "    corr_weights=corr_weights,\n",
        "    tsne_save_dir=os.path.join(training_args.output_dir, \"tsne_plots\"),\n",
        "    tsne_label_mappings=label_name_mappings,\n",
        ")\n",
        "trainer_ref[\"trainer\"] = trainer\n",
        "trainer\n",
        "trainer.remove_callback(PrinterCallback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 評価→学習→テスト\n",
        "`train.py` と同様に、初期 `evaluate` → `train` → `test (evaluate on test split)` の順に実行してログを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "ename": "StopIteration",
          "evalue": "Caught StopIteration in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/model/modeling_encoders.py\", line 270, in forward\n    \"token_type_ids_2\": token_type_ids_2,\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nStopIteration\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m baseline_metrics = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m baseline_metrics\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/clf_trainer.py:242\u001b[39m, in \u001b[36mCustomTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28mself\u001b[39m._current_eval_embedding_mode = \u001b[33m\"\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_original_now \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._current_eval_embedding_mode == \u001b[33m\"\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/transformers/trainer.py:4200\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4197\u001b[39m start_time = time.time()\n\u001b[32m   4199\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4200\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4201\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4210\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/clf_trainer.py:261\u001b[39m, in \u001b[36mCustomTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluation_loop\u001b[39m(\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    255\u001b[39m     dataloader,\n\u001b[32m   (...)\u001b[39m\u001b[32m    259\u001b[39m     metric_key_prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    260\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     output = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluation_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m._last_eval_predictions = output.predictions\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._last_eval_label_ids = output.label_ids\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/transformers/trainer.py:4395\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4392\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4394\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4395\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4396\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4397\u001b[39m inputs_decode = (\n\u001b[32m   4398\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4399\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/clf_trainer.py:226\u001b[39m, in \u001b[36mCustomTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprediction_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, prediction_loss_only, ignore_keys=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/clf_trainer.py:209\u001b[39m, in \u001b[36mCustomTrainer.evaluation_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m    207\u001b[39m model.eval()\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     loss, logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# print(f\"eval loss: {loss}\")\u001b[39;00m\n\u001b[32m    212\u001b[39m labels_tensor = inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# torch.Tensor\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/clf_trainer.py:163\u001b[39m, in \u001b[36mCustomTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m active_heads = extract_unique_strings(inputs[\u001b[33m\"\u001b[39m\u001b[33mactive_heads\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    161\u001b[39m total_loss = torch.tensor(\u001b[32m0.0\u001b[39m, device=device, requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m single_loss, outputs1 = \u001b[43mcompute_single_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    165\u001b[39m     total_loss = total_loss + single_loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/loss_function.py:24\u001b[39m, in \u001b[36mcompute_single_loss\u001b[39m\u001b[34m(trainer, model, inputs, active_heads, device)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inputs:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, {}\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m loss: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     26\u001b[39m labels = inputs.get(\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:194\u001b[39m, in \u001b[36mDataParallel.forward\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module(*inputs[\u001b[32m0\u001b[39m], **module_kwargs[\u001b[32m0\u001b[39m])\n\u001b[32m    193\u001b[39m replicas = \u001b[38;5;28mself\u001b[39m.replicate(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.device_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gather(outputs, \u001b[38;5;28mself\u001b[39m.output_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:213\u001b[39m, in \u001b[36mDataParallel.parallel_apply\u001b[39m\u001b[34m(self, replicas, inputs, kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparallel_apply\u001b[39m(\n\u001b[32m    211\u001b[39m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[32m    212\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Any]:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:127\u001b[39m, in \u001b[36mparallel_apply\u001b[39m\u001b[34m(modules, inputs, kwargs_tup, devices)\u001b[39m\n\u001b[32m    125\u001b[39m     output = results[i]\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m         \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     outputs.append(output)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/_utils.py:750\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
            "\u001b[31mStopIteration\u001b[39m: Caught StopIteration in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/SLBERT/my-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/remote/csifs1/disk3/users/yama11235/yama11235/Sentiment-Circle/utils/model/modeling_encoders.py\", line 270, in forward\n    \"token_type_ids_2\": token_type_ids_2,\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nStopIteration\n"
          ]
        }
      ],
      "source": [
        "baseline_metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "baseline_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_result = trainer.train()\n",
        "train_metrics = train_result.metrics\n",
        "train_metrics[\"train_samples\"] = len(train_dataset)\n",
        "train_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_metrics = trainer.evaluate(eval_dataset=predict_dataset)\n",
        "test_metrics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my-project",
      "language": "python",
      "name": "my-project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
